{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a7e8754a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-05-24T10:56:14.164009Z",
     "iopub.status.busy": "2024-05-24T10:56:14.163315Z",
     "iopub.status.idle": "2024-05-24T10:56:14.864479Z",
     "shell.execute_reply": "2024-05-24T10:56:14.863477Z"
    },
    "jupyter": {
     "source_hidden": true
    },
    "papermill": {
     "duration": 0.708212,
     "end_time": "2024-05-24T10:56:14.867091",
     "exception": false,
     "start_time": "2024-05-24T10:56:14.158879",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/unique-videos/unique_videos.csv\n",
      "/kaggle/input/duration-5min-1sthalf/duration_5min_1stHalf.xlsx\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "937f9392",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:56:14.873969Z",
     "iopub.status.busy": "2024-05-24T10:56:14.873581Z",
     "iopub.status.idle": "2024-05-24T10:57:37.977270Z",
     "shell.execute_reply": "2024-05-24T10:57:37.975875Z"
    },
    "papermill": {
     "duration": 83.109198,
     "end_time": "2024-05-24T10:57:37.979361",
     "exception": false,
     "start_time": "2024-05-24T10:56:14.870163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/openai/whisper.git\r\n",
      "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-7zehndo7\r\n",
      "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-7zehndo7\r\n",
      "  Resolved https://github.com/openai/whisper.git to commit ba3f3cd54b0e5b8ce1ab3de13e32122d0d5f98ab\r\n",
      "  Installing build dependencies ... \u001b[?25l-\b \b\\\b \b|\b \b/\b \b-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25l-\b \bdone\r\n",
      "\u001b[?25hRequirement already satisfied: numba in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (0.58.1)\r\n",
      "Requirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (1.26.4)\r\n",
      "Requirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (2.1.2)\r\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (4.66.1)\r\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from openai-whisper==20231117) (10.2.0)\r\n",
      "Collecting tiktoken (from openai-whisper==20231117)\r\n",
      "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\r\n",
      "Collecting triton<3,>=2.0.0 (from openai-whisper==20231117)\r\n",
      "  Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from triton<3,>=2.0.0->openai-whisper==20231117) (3.13.1)\r\n",
      "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /opt/conda/lib/python3.10/site-packages (from numba->openai-whisper==20231117) (0.41.1)\r\n",
      "Requirement already satisfied: regex>=2022.1.18 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2023.12.25)\r\n",
      "Requirement already satisfied: requests>=2.26.0 in /opt/conda/lib/python3.10/site-packages (from tiktoken->openai-whisper==20231117) (2.31.0)\r\n",
      "Requirement already satisfied: typing-extensions in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (4.9.0)\r\n",
      "Requirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (1.12)\r\n",
      "Requirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.2.1)\r\n",
      "Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (3.1.2)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->openai-whisper==20231117) (2024.2.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (3.6)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (1.26.18)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231117) (2024.2.2)\r\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->openai-whisper==20231117) (2.1.3)\r\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->openai-whisper==20231117) (1.3.0)\r\n",
      "Downloading triton-2.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (168.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.1/168.1 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hBuilding wheels for collected packages: openai-whisper\r\n",
      "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l-\b \b\\\b \bdone\r\n",
      "\u001b[?25h  Created wheel for openai-whisper: filename=openai_whisper-20231117-py3-none-any.whl size=802826 sha256=772820e027e539c76a07f0fb77d257f0406c2f6e19ab962d3452ed0c5569861d\r\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-fsgvpu8m/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\r\n",
      "Successfully built openai-whisper\r\n",
      "Installing collected packages: triton, tiktoken, openai-whisper\r\n",
      "Successfully installed openai-whisper-20231117 tiktoken-0.7.0 triton-2.3.0\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install git+https://github.com/openai/whisper.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6705f716",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:57:38.144040Z",
     "iopub.status.busy": "2024-05-24T10:57:38.143714Z",
     "iopub.status.idle": "2024-05-24T10:57:54.212026Z",
     "shell.execute_reply": "2024-05-24T10:57:54.210751Z"
    },
    "papermill": {
     "duration": 16.153545,
     "end_time": "2024-05-24T10:57:54.214643",
     "exception": false,
     "start_time": "2024-05-24T10:57:38.061098",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yt-dlp\r\n",
      "  Downloading yt_dlp-2024.4.9-py3-none-any.whl.metadata (165 kB)\r\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.0/166.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hRequirement already satisfied: brotli in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (1.0.9)\r\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (2024.2.2)\r\n",
      "Collecting mutagen (from yt-dlp)\r\n",
      "  Downloading mutagen-1.47.0-py3-none-any.whl.metadata (1.7 kB)\r\n",
      "Collecting pycryptodomex (from yt-dlp)\r\n",
      "  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\r\n",
      "Requirement already satisfied: requests<3,>=2.31.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (2.31.0)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.26.17 in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (1.26.18)\r\n",
      "Requirement already satisfied: websockets>=12.0 in /opt/conda/lib/python3.10/site-packages (from yt-dlp) (12.0)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.3.2)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.31.0->yt-dlp) (3.6)\r\n",
      "Downloading yt_dlp-2024.4.9-py3-none-any.whl (3.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading mutagen-1.47.0-py3-none-any.whl (194 kB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.4/194.4 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hDownloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\r\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m76.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\r\n",
      "\u001b[?25hInstalling collected packages: pycryptodomex, mutagen, yt-dlp\r\n",
      "Successfully installed mutagen-1.47.0 pycryptodomex-3.20.0 yt-dlp-2024.4.9\r\n"
     ]
    }
   ],
   "source": [
    "!pip install yt-dlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "03a41f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T10:57:54.406214Z",
     "iopub.status.busy": "2024-05-24T10:57:54.405468Z",
     "iopub.status.idle": "2024-05-24T19:41:35.951584Z",
     "shell.execute_reply": "2024-05-24T19:41:35.950781Z"
    },
    "papermill": {
     "duration": 31421.64223,
     "end_time": "2024-05-24T19:41:35.953785",
     "exception": false,
     "start_time": "2024-05-24T10:57:54.311555",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   0%|          | 0/4246 [00:00<?, ?it/s]\n",
      "  0%|                                              | 0.00/72.1M [00:00<?, ?iB/s]\u001b[A/opt/conda/lib/python3.10/site-packages/whisper/__init__.py:65: UserWarning: /root/.cache/whisper/tiny.pt exists, but the SHA256 checksum does not match; re-downloading the file\n",
      "  warnings.warn(\n",
      "\n",
      "  7%|██▍                                  | 4.81M/72.1M [00:00<00:01, 50.1MiB/s]\u001b[A\n",
      "\n",
      "  0%|                                              | 0.00/72.1M [00:00<?, ?iB/s]\u001b[A\u001b[A\n",
      " 31%|███████████▋                          | 22.1M/72.1M [00:00<00:00, 127MiB/s]\u001b[A\n",
      "\n",
      "  8%|██▉                                  | 5.78M/72.1M [00:00<00:01, 60.6MiB/s]\u001b[A\u001b[A\n",
      " 53%|████████████████████▎                 | 38.5M/72.1M [00:00<00:00, 147MiB/s]\u001b[A\n",
      "\n",
      " 24%|████████▋                            | 17.0M/72.1M [00:00<00:00, 94.1MiB/s]\u001b[A\u001b[A\n",
      " 73%|███████████████████████████▋          | 52.5M/72.1M [00:00<00:00, 147MiB/s]\u001b[A\n",
      "\n",
      " 36%|█████████████▍                       | 26.2M/72.1M [00:00<00:00, 95.2MiB/s]\u001b[A\u001b[A\n",
      "100%|██████████████████████████████████████| 72.1M/72.1M [00:00<00:00, 146MiB/s]\n",
      "\n",
      "\n",
      " 49%|██████████████████                   | 35.3M/72.1M [00:00<00:00, 62.3MiB/s]\u001b[A\u001b[A\n",
      "\n",
      " 59%|█████████████████████▋               | 42.3M/72.1M [00:00<00:00, 65.1MiB/s]\u001b[A\u001b[A\n",
      "\n",
      " 68%|█████████████████████████▎           | 49.3M/72.1M [00:00<00:00, 66.5MiB/s]\u001b[A\u001b[A\n",
      "\n",
      " 78%|████████████████████████████▊        | 56.2M/72.1M [00:00<00:00, 51.3MiB/s]\u001b[A\u001b[A\n",
      "\n",
      "100%|█████████████████████████████████████| 72.1M/72.1M [00:01<00:00, 67.3MiB/s]\n",
      "Processing videos:   5%|▌         | 232/4246 [30:42<10:49:50,  9.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID Rc4jWMznRqQ: ERROR: [youtube] Rc4jWMznRqQ: Private video. Sign in if you've been granted access to this video\n",
      "Attempt 2 failed for video ID Rc4jWMznRqQ: ERROR: [youtube] Rc4jWMznRqQ: Private video. Sign in if you've been granted access to this video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   5%|▌         | 233/4246 [30:45<8:44:34,  7.84s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 3 failed for video ID Rc4jWMznRqQ: ERROR: [youtube] Rc4jWMznRqQ: Private video. Sign in if you've been granted access to this video\n",
      "Failed to download or convert audio for video ID Rc4jWMznRqQ after 3 attempts.\n",
      "Error message: ERROR: [youtube] Rc4jWMznRqQ: Private video. Sign in if you've been granted access to this video\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   7%|▋         | 276/4246 [34:41<3:51:16,  3.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID TaAHETxYvas: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:   7%|▋         | 308/4246 [39:34<2:18:59,  2.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID jkcyHUHfrLA: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  10%|▉         | 411/4246 [46:28<3:44:59,  3.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID zKK-5bRFcbs: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  11%|█▏        | 479/4246 [51:57<4:20:20,  4.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 7bO0dDycr9c: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  13%|█▎        | 537/4246 [56:08<2:46:13,  2.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID soWwSlTYdAI: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  14%|█▎        | 579/4246 [59:49<4:05:30,  4.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID _8oV8FBLZS0: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  14%|█▍        | 586/4246 [1:00:20<3:45:04,  3.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID zjoauhyCpYc: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  14%|█▍        | 601/4246 [1:01:32<2:59:13,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID EYzugJPrgpk: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  17%|█▋        | 727/4246 [1:14:25<7:44:38,  7.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID sxG5THYWvL4: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  20%|█▉        | 848/4246 [1:27:26<8:42:29,  9.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID Zhshc1f_T_A: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  23%|██▎       | 976/4246 [1:44:22<5:15:49,  5.79s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID M11qep9-mB4: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  26%|██▌       | 1098/4246 [2:01:10<5:00:20,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID iNT30LsQmEQ: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  27%|██▋       | 1139/4246 [2:06:42<5:01:27,  5.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID YOCPH92_euQ: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  28%|██▊       | 1182/4246 [2:12:25<8:49:03, 10.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID wvEXiNbMBcE: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  32%|███▏      | 1344/4246 [2:32:36<6:26:33,  7.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID vf_HAyGo-r8: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  35%|███▌      | 1507/4246 [2:54:14<3:18:09,  4.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID FNwdqiZRBag: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  36%|███▌      | 1518/4246 [2:56:02<7:30:09,  9.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID nzTmSeeY0Gg: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  37%|███▋      | 1552/4246 [2:59:57<4:26:11,  5.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID lRxHrE5C_kE: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  37%|███▋      | 1569/4246 [3:01:57<3:16:15,  4.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID pL42FLe6H7I: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  37%|███▋      | 1590/4246 [3:04:33<4:37:46,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID yfrguznLkTY: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  38%|███▊      | 1606/4246 [3:06:45<5:39:43,  7.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID vkbl81JC9WI: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  40%|████      | 1708/4246 [3:20:19<4:24:56,  6.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 6GEn-zHxTRA: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  46%|████▌     | 1955/4246 [3:51:31<3:44:35,  5.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 0TksSR7r0qg: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  46%|████▌     | 1959/4246 [3:51:55<3:18:31,  5.21s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID Fd5Ks-ZxN5U: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  57%|█████▋    | 2399/4246 [4:43:36<3:20:21,  6.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID NOYVIVoqcss: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  59%|█████▉    | 2524/4246 [4:57:27<2:26:59,  5.12s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 8qwIhyp6OrI: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  60%|█████▉    | 2532/4246 [4:58:42<3:08:15,  6.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID jDuD3m8zHW8: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  64%|██████▍   | 2732/4246 [5:22:37<3:45:23,  8.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 6l2JQpvDJ0o: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  65%|██████▍   | 2758/4246 [5:25:28<2:23:55,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID KX_I2M3yXFo: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  66%|██████▌   | 2800/4246 [5:30:16<2:10:27,  5.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID eMqNrD-rRtE: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  68%|██████▊   | 2886/4246 [5:41:23<2:02:02,  5.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID T1xtTN2ZFm0: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  72%|███████▏  | 3056/4246 [6:02:30<3:01:04,  9.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID rnUtgQiZisw: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  73%|███████▎  | 3118/4246 [6:10:20<1:38:49,  5.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID qq1hVu79mAc: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  75%|███████▍  | 3164/4246 [6:16:42<2:56:24,  9.78s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 9joLaljXmko: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  78%|███████▊  | 3303/4246 [6:36:26<1:34:12,  5.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID my76MRLfLg8: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  78%|███████▊  | 3325/4246 [6:39:50<2:06:37,  8.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID L4tlVYOseg0: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  79%|███████▉  | 3358/4246 [6:44:37<1:59:33,  8.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID uQiN5_wzi7c: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  82%|████████▏ | 3491/4246 [7:03:47<1:26:21,  6.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID 7AhLz_YBSk4: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  89%|████████▉ | 3797/4246 [7:46:28<43:23,  5.80s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID i2tlB19ru7c: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos:  93%|█████████▎| 3944/4246 [8:04:29<33:54,  6.74s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attempt 1 failed for video ID Y46ZmxUhOzI: ERROR: unable to download video data: HTTP Error 403: Forbidden\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing videos: 100%|██████████| 4246/4246 [8:43:36<00:00,  7.40s/it]\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "\n",
    "import os\n",
    "import tempfile\n",
    "import subprocess\n",
    "import pandas as pd\n",
    "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "import whisper\n",
    "from tqdm import tqdm\n",
    "\n",
    "def download_audio(video_id, retries=3):\n",
    "    \"\"\"Download the audio from a YouTube video using yt-dlp and convert it to WAV format.\"\"\"\n",
    "    output_path_wav = f\"{tempfile.mktemp(suffix='.wav')}\"\n",
    "    command = [\n",
    "        'yt-dlp',\n",
    "        '-x', '--audio-format', 'wav',\n",
    "        '--audio-quality', '9',  \n",
    "        '-o', output_path_wav,\n",
    "        f'https://www.youtube.com/watch?v={video_id}'\n",
    "    ]\n",
    "    for attempt in range(retries):\n",
    "        try:\n",
    "            result = subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "            return output_path_wav\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"Attempt {attempt + 1} failed for video ID {video_id}: {e.stderr.decode().strip()}\")\n",
    "            if attempt == retries - 1:\n",
    "                print(f\"Failed to download or convert audio for video ID {video_id} after {retries} attempts.\")\n",
    "                print(f\"Error message: {e.stderr.decode().strip()}\")\n",
    "    return None\n",
    "\n",
    "def transcribe_audio(audio_path):\n",
    "    \"\"\"Transcribe audio using Whisper.\"\"\"\n",
    "    try:\n",
    "        model = whisper.load_model(\"tiny\")\n",
    "        result = model.transcribe(audio_path)\n",
    "        return result['text']\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to transcribe audio: {e}\")\n",
    "        return \"Transcription failed\"\n",
    "\n",
    "def process_video(video_id, channel_id):\n",
    "    \"\"\"Process a single video given by video_id and include channel_id.\"\"\"\n",
    "    audio_path = download_audio(video_id)\n",
    "    if audio_path:\n",
    "        transcription = transcribe_audio(audio_path)\n",
    "        os.remove(audio_path)\n",
    "    else:\n",
    "        transcription = \"No transcription available\"\n",
    "    return video_id, channel_id, transcription\n",
    "\n",
    "def process_videos(video_data):\n",
    "    \"\"\"Download and transcribe videos listed by their YouTube IDs using multithreading, including channel IDs.\"\"\"\n",
    "    transcriptions = []\n",
    "    output_csv = \"/kaggle/working/test.csv\"\n",
    "    \n",
    "    with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "        future_to_video = {executor.submit(process_video, row['VideoID'], row['channelId']): row for index, row in video_data.iterrows()}\n",
    "        for i, future in tqdm(enumerate(as_completed(future_to_video), start=1), total=len(video_data), desc=\"Processing videos\"):\n",
    "            try:\n",
    "                video_id, channel_id, transcription = future.result()\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing video: {e}\")\n",
    "                video_id = future_to_video[future]['VideoID']\n",
    "                channel_id = future_to_video[future]['channelId']\n",
    "                transcription = \"Error during processing\"\n",
    "            transcriptions.append({'VideoID': video_id, 'ChannelID': channel_id, 'Transcription': transcription})\n",
    "            # Save transcriptions to CSV file after each iteration\n",
    "            pd.DataFrame(transcriptions).to_csv(output_csv, index=False)\n",
    "    \n",
    "    return pd.DataFrame(transcriptions)\n",
    "# Example usage\n",
    "df2 = pd.read_csv('/kaggle/input/unique-videos/unique_videos.csv')\n",
    "# df2 = df2[24285:25000]\n",
    "df = process_videos(df2)\n",
    "df.to_csv(\"/kaggle/working/duration_5min_2ndstHalf-unique.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b7ab6154",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-05-24T19:41:36.817673Z",
     "iopub.status.busy": "2024-05-24T19:41:36.816749Z",
     "iopub.status.idle": "2024-05-24T19:41:36.825275Z",
     "shell.execute_reply": "2024-05-24T19:41:36.824041Z"
    },
    "papermill": {
     "duration": 0.448117,
     "end_time": "2024-05-24T19:41:36.827492",
     "exception": false,
     "start_time": "2024-05-24T19:41:36.379375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# import warnings\n",
    "# warnings.filterwarnings(\"ignore\", message=\"FP16 is not supported on CPU; using FP32 instead\")\n",
    "\n",
    "# import os\n",
    "# import tempfile\n",
    "# import subprocess\n",
    "# import pandas as pd\n",
    "# from concurrent.futures import ThreadPoolExecutor, as_completed\n",
    "# import whisper\n",
    "# from tqdm import tqdm\n",
    "\n",
    "# def download_audio(video_id):\n",
    "#     \"\"\"Download the audio from a YouTube video using yt-dlp and convert it to WAV format.\"\"\"\n",
    "#     output_path_wav = f\"{tempfile.mktemp(suffix='.wav')}\"\n",
    "#     try:\n",
    "#         command = [\n",
    "#             'yt-dlp',\n",
    "#             '-x', '--audio-format', 'wav',\n",
    "#             '--audio-quality', '0',  # Best quality\n",
    "#             '-o', output_path_wav,\n",
    "#             f'https://www.youtube.com/watch?v={video_id}'\n",
    "#         ]\n",
    "#         subprocess.run(command, check=True, stdout=subprocess.PIPE, stderr=subprocess.PIPE)\n",
    "#         return output_path_wav\n",
    "#     except subprocess.CalledProcessError as e:\n",
    "#         print(f\"Failed to download or convert audio for video ID {video_id}: {e}\")\n",
    "#         return None\n",
    "\n",
    "# def transcribe_audio(audio_path):\n",
    "#     \"\"\"Transcribe audio using Whisper.\"\"\"\n",
    "#     try:\n",
    "#         model = whisper.load_model(\"tiny\")\n",
    "#         result = model.transcribe(audio_path)\n",
    "#         return result['text']\n",
    "#     except Exception as e:\n",
    "#         print(f\"Failed to transcribe audio: {e}\")\n",
    "#         return \"Transcription failed\"\n",
    "\n",
    "# def process_video(video_id, channel_id):\n",
    "#     \"\"\"Process a single video given by video_id and include channel_id.\"\"\"\n",
    "#     audio_path = download_audio(video_id)\n",
    "#     if audio_path:\n",
    "#         transcription = transcribe_audio(audio_path)\n",
    "#         os.remove(audio_path)\n",
    "#     else:\n",
    "#         transcription = \"No transcription available\"\n",
    "#     return video_id, channel_id, transcription\n",
    "\n",
    "# def process_videos(video_data):\n",
    "#     \"\"\"Download and transcribe videos listed by their YouTube IDs using multithreading, including channel IDs.\"\"\"\n",
    "#     transcriptions = []\n",
    "#     output_csv = \"/kaggle/working/test.csv\"\n",
    "    \n",
    "#     with ThreadPoolExecutor(max_workers=3) as executor:\n",
    "#         future_to_video = {executor.submit(process_video, row['id'], row['channelId']): row for index, row in video_data.iterrows()}\n",
    "#         for i, future in tqdm(enumerate(as_completed(future_to_video), start=1), total=len(video_data), desc=\"Processing videos\"):\n",
    "#             try:\n",
    "#                 video_id, channel_id, transcription = future.result()\n",
    "#             except Exception as e:\n",
    "#                 print(f\"Error processing video: {e}\")\n",
    "#                 video_id = future_to_video[future]['id']\n",
    "#                 channel_id = future_to_video[future]['channelId']\n",
    "#                 transcription = \"Error during processing\"\n",
    "#             transcriptions.append({'VideoID': video_id, 'ChannelID': channel_id, 'Transcription': transcription})\n",
    "#             # Save transcriptions to CSV file after each iteration\n",
    "#             pd.DataFrame(transcriptions).to_csv(output_csv, index=False)\n",
    "    \n",
    "#     return pd.DataFrame(transcriptions)\n",
    "\n",
    "# # Example usage\n",
    "# df2 = pd.read_excel('/kaggle/input/duration-5min-1sthalf/duration_5min_1stHalf.xlsx')\n",
    "# df_slice = df2.iloc[10000:15000]  # Selects rows 5001 to 7000\n",
    "#   # Load only the first 50 for example, assuming 'id' and 'channelId' are columns\n",
    "# df = process_videos(df_slice)\n",
    "# df.to_csv(\"/kaggle/working/duration_5min_2ndstHalf10000-15000.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 5026451,
     "sourceId": 8438381,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5076820,
     "sourceId": 8505663,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30698,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 31526.980369,
   "end_time": "2024-05-24T19:41:38.449822",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-05-24T10:56:11.469453",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
